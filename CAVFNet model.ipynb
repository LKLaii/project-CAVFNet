{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3d0fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as io\n",
    "import sklearn\n",
    "\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "from paddle.io import Dataset\n",
    "from paddle.io import DataLoader\n",
    "from paddle.io import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d458300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BAP(nn.Layer):\n",
    "    def __init__(self,in_features=8): \n",
    "        super(BAP,self).__init__()   \n",
    "#         self.weight = nn.Sequential(\n",
    "#             nn.Linear(in_features=in_features, out_features=in_features*2),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(in_features=in_features*2, out_features=in_features),\n",
    "#             nn.Sigmoid())\n",
    "#         self.flatten = nn.Flatten()\n",
    "    def forward(self, x):   \n",
    "        w = paddle.mean(x, axis=-1)\n",
    "        w = paddle.mean(w, axis=1)\n",
    "#         w = self.flatten(w)\n",
    "#         w = self.weight(w)\n",
    "        w = w.reshape([x.shape[0]]+[1]+[x.shape[2]]+[1])\n",
    "        return w\n",
    "\n",
    "class CAFM(nn.Layer):\n",
    "    def __init__(self,in_channels,Gamma=0): \n",
    "        super(CAFM,self).__init__()   \n",
    "#         self.conv1 = nn.Conv2D(in_channels=in_channels,out_channels=1,kernel_size=1)\n",
    "        self.bap = BAP()\n",
    "        self.gamma_ = paddle.create_parameter(\n",
    "            shape=[1], dtype='float32',\n",
    "            default_initializer= paddle.nn.initializer.Constant(Gamma) )\n",
    "    def forward(self, c, v, f):   \n",
    "        c = self.bap(c)\n",
    "        f1 = f*c\n",
    "        gamma = F.sigmoid(self.gamma_)\n",
    "        f2 = f*gamma + v*(1-gamma)\n",
    "        f = f1+f2\n",
    "        return f\n",
    "# paddle.summary(CAFM(3,0),[(2,3,8,256),(2,3,8,256),(2,3,8,256)])##batch @ channel @ band @ T\n",
    "\n",
    "class con_bn_relu_maxpool(nn.Layer):\n",
    "    def __init__(self,in_channels,out_channels,kernel_size=1,stride=1,padding=0): \n",
    "        super(con_bn_relu_maxpool,self).__init__() \n",
    "        self.CBRM = nn.Sequential(   \n",
    "            nn.Conv2D(in_channels, out_channels, kernel_size,stride,padding),\n",
    "            nn.BatchNorm2D(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2D(kernel_size=(1,2),stride=(1,2)),\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        x= self.CBRM(x)\n",
    "        return x\n",
    "\n",
    "class Classifier(nn.Layer):\n",
    "    def __init__(self,in_features,out_features=[128,3], drop=0.4):\n",
    "        super(Classifier,self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            #nn.Dropout(drop),\n",
    "            nn.Linear(in_features, out_features[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_features[0],out_features[1]),\n",
    "            nn.Softmax(), )\n",
    "    def forward(self,x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "class Classifier_(nn.Layer):\n",
    "    def __init__(self,in_features,out_features=[128,3], drop=0.4):\n",
    "        super(Classifier_,self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(in_features, out_features[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_features[0],out_features[1]))\n",
    "    def forward(self,x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "class B_att(nn.Layer):\n",
    "    def __init__(self,in_features=8): \n",
    "        super(B_att,self).__init__()   \n",
    "        self.weight = nn.Sequential(\n",
    "            nn.Linear(in_features=in_features, out_features=in_features*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=in_features*2, out_features=in_features),\n",
    "            nn.Sigmoid())\n",
    "        self.flatten = nn.Flatten()\n",
    "    def forward(self, x):   \n",
    "        w = paddle.mean(x, axis=-1)\n",
    "        w = self.flatten(w)\n",
    "        w = self.weight(w)\n",
    "        w = w.reshape(x.shape[:3]+[1])\n",
    "        x = x*w + x\n",
    "        return x\n",
    "    \n",
    "class CAVFNet(nn.Layer):\n",
    "    def __init__(self, num_classes=8): \n",
    "        super(CAVFNet,self).__init__()   \n",
    "        self.layer11 = con_bn_relu_maxpool(1,  16, (3,3), (1,2) ,(1,1) )\n",
    "        self.layer12 = con_bn_relu_maxpool(16, 32, (3,3), (1,2) ,(1,1) )\n",
    "        self.layer13 = con_bn_relu_maxpool(32, 32, (3,3), (1,2) ,(1,1) )\n",
    "        self.layer21 = con_bn_relu_maxpool(1,  16, (3,3), (1,2) ,(1,1) )\n",
    "        self.layer22 = con_bn_relu_maxpool(16, 32, (3,3), (1,2) ,(1,1) )\n",
    "        self.layer23 = con_bn_relu_maxpool(32, 32, (3,3), (1,2) ,(1,1) )\n",
    "        self.layer31 = con_bn_relu_maxpool(1,  16, (3,3), (1,2) ,(1,1) )\n",
    "        self.layer32 = con_bn_relu_maxpool(16, 32, (3,3), (1,2) ,(1,1) )\n",
    "        self.layer33 = con_bn_relu_maxpool(32, 32, (3,3), (1,2) ,(1,1) )\n",
    "        self.cafm1 = CAFM(16,0.5)\n",
    "        self.cafm2 = CAFM(32,0.5)\n",
    "        self.cafm3 = CAFM(32,0.5)\n",
    "        self.ba = B_att(8)\n",
    "\n",
    "        self.fc1 = Classifier_(32*8*4,[128,num_classes],0.4)\n",
    "        self.fc2 = Classifier_(32*8*4,[128,num_classes],0.4)\n",
    "        self.fc3 = Classifier_(32*8*4,[128,num_classes],0.4)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features=num_classes*2,out_features=2),\n",
    "            nn.Softmax() )\n",
    "    def forward(self, v, c):    \n",
    "        frames_0 = self.layer11(c)\n",
    "        frames_1 = self.layer21(v)\n",
    "        fusion = self.layer31(v)\n",
    "        fusion = self.cafm1(frames_0,frames_1,fusion)\n",
    "        frames_0 = self.layer12(frames_0)\n",
    "        frames_1 = self.layer22(frames_1)\n",
    "        fusion = self.layer32(fusion)\n",
    "        fusion = self.cafm2(frames_0,frames_1,fusion)\n",
    "        frames_0 = self.layer13(frames_0)\n",
    "        frames_1 = self.layer23(frames_1)\n",
    "        fusion = self.layer33(fusion)\n",
    "        fusion = self.cafm3(frames_0,frames_1,fusion)\n",
    "        frames_0 = F.softmax(self.fc1(frames_0))\n",
    "        frames_1 = self.fc2(frames_1)\n",
    "        fusion  = self.fc3(fusion)\n",
    "        xi = paddle.concat([frames_1, fusion],axis=1)\n",
    "        xi = self.fc(xi)\n",
    "        frames_1 = F.softmax(frames_1)\n",
    "        fusion = F.softmax(fusion)\n",
    "        fusion = frames_1*(xi[:,0]).reshape([v.shape[0],1]) + fusion *(xi[:,1]).reshape([v.shape[0],1])      \n",
    "        return  fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ae6c42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
